{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c656ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud\n",
    "!pip install sklearn\n",
    "!pip install tensorflow\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b89eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_dict = {\n",
    "    \"num\":{ 0: \"sadness\",\n",
    "        1: \"anger\",\n",
    "        2: \"love\",\n",
    "        3: \"surprise\",\n",
    "        4: \"fear\",\n",
    "        5: \"joy\"}\n",
    "}\n",
    "\n",
    "tag_id_dict = {}\n",
    "for key, value in emotions_dict[\"num\"].items():\n",
    "    tag_id_dict[value] = key\n",
    "\n",
    "emotions_dict[\"num\"] = tag_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b40cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/NEGIN COMPUTER/Downloads/archive/train.txt', names=['Text', 'label'], delimiter=';')\n",
    "val = pd.read_csv('C:/Users/NEGIN COMPUTER/Downloads/archive/val.txt', names=['Text', 'label'], delimiter=';')\n",
    "test = pd.read_csv('C:/Users/NEGIN COMPUTER/Downloads/archive/test.txt', names=['Text', 'label'], delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7af404",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20982707",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3fa747",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf35f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c6ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea69369",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = train[train.duplicated() == True].index\n",
    "train.drop(index, axis = 0, inplace = True)\n",
    "train.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = train[train['Text'].duplicated() == True].index\n",
    "train.drop(index, axis = 0, inplace = True)\n",
    "train.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def preprocess_data(train, test, val, max_length=None):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(train)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "    if max_length is None:\n",
    "        max_length = max(len(sequence.split()) for sequence in train)\n",
    "\n",
    "    train_sequences = tokenizer.texts_to_sequences(train)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test)\n",
    "    val_sequences = tokenizer.texts_to_sequences(val)\n",
    "\n",
    "    x_train = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n",
    "    x_test = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
    "    x_val = pad_sequences(val_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "    print(\"x_train shape:\", x_train.shape)\n",
    "    print(\"x_test shape:\", x_test.shape)\n",
    "    print(\"x_val shape:\", x_val.shape)\n",
    "\n",
    "    return x_train, x_test, x_val, vocab_size, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fcffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_val, VOCAB_SIZE, tokenizer = data_preprocessing(train, test, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7600fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_preprocessing(data):\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(data[\"label\"].to_list())\n",
    "    y = y.reshape(-1, 1)\n",
    "    return y\n",
    "\n",
    "y_train = label_preprocessing(train)\n",
    "y_test = label_preprocessing(test)\n",
    "y_val = label_preprocessing(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "labels = ['sadness', 'anger', 'love', 'surprise', 'fear','joy']\n",
    "encoder.fit(labels)\n",
    "\n",
    "VOCAB_SIZE = 1000\n",
    "embedding_dim = 64\n",
    "hidden_units = 10\n",
    "num_labels = len(encoder.classes_)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(30,))\n",
    "\n",
    "x = tf.keras.layers.Embedding(VOCAB_SIZE, embedding_dim, input_length=30)(inputs)\n",
    "\n",
    "x = tf.keras.layers.LSTM(hidden_units, return_sequences=True)(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(num_labels, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=\"sparse_categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=20, batch_size=32,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e21d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82829835",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predict:\n",
    "    def __init__(self, model, tokenizer, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = Tokenizer()\n",
    "    \n",
    "    def predict(self, txt):\n",
    "        x = self.tokenizer.texts_to_sequences([txt])\n",
    "        x = tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=30)\n",
    "        predictions = self.model.predict(x)\n",
    "        predicted_label_index = np.argmax(predictions[0])\n",
    "        predicted_label = self.emotions_dict[\"num\"][predicted_label_index]\n",
    "        return predicted_label\n",
    "\n",
    "predict = Predict(model, tokenizer, emotions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf2c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = Predict(model, tokenizer)\n",
    "predict.predict(\"im so sad!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b4adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
